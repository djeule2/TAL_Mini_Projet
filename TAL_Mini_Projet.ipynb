{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "another-application",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c7/HEIG-VD_Logo_96x29_RVB_ROUGE.png\" alt=\"HEIG-VD Logo\" width=\"250\"/>\n",
    "\n",
    "# Cours TAL - Mini - Projet\n",
    "# Classification de dépêches d’agence avec NLTK\n",
    "\n",
    "**Objectifs**\n",
    "\n",
    "L’objectif de ce projet est de réaliser des expériences de *classification de documents* sous NLTK avec \n",
    "le corpus de dépêches Reuters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-holmes",
   "metadata": {},
   "source": [
    "*  le corpus Reuters contient environ 10'000 dépêches datant des années 1980, et il est fourni avec NLTK comme expliqué dans le [livre NLTK, ch.2](http://www.nltk.org/book/ch02.html), §1.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "greek-contract",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to C:\\Users\\Lenovo\n",
      "[nltk_data]     T50s\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "nltk.downloader.Downloader().download('reuters') \n",
    "# à exécuter une seule fois pour télécharger les fichiers localement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-gothic",
   "metadata": {},
   "source": [
    "* Le code suivant illustre certaines de ses fonctionnalités en imprimant des informations de base pour la collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "martial-wonder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10788 documents\n",
      "7769 total train documents\n",
      "3019 total test documents\n",
      "90 categories\n",
      "['BUNDESBANK', 'ALLOCATES', '6', '.', '1', 'BILLION', ...]\n",
      "BUNDESBANK ALLOCATES 6.1 BILLION MARKS IN TENDER\n",
      "  The Bundesbank accepted bids for 6.1\n",
      "  billion marks at today's tender for a 28-day securities\n",
      "  repurchase pact at a fixed rate of 3.80 pct, a central bank\n",
      "  spokesman said.\n",
      "      Banks, which bid for a total 12.2 billion marks liquidity,\n",
      "  will be credited with the funds allocated today and must buy\n",
      "  back securities pledged on May 6.\n",
      "      Some 14.9 billion marks will drain from the market today as\n",
      "  an earlier pact expires, so the Bundesbank is effectively\n",
      "  withdrawing a net 8.1 billion marks from the market with\n",
      "  today's allocation.\n",
      "      A Bundesbank spokesman said in answer to enquiries that the\n",
      "  withdrawal of funds did not reflect a tightening of credit\n",
      "  policy, but was to be seen in the context of plentiful\n",
      "  liquidity in the banking system.\n",
      "      Banks held an average 59.3 billion marks at the Bundesbank\n",
      "  over the first six days of the month, well clear of the likely\n",
      "  April minimum reserve requirement of 51 billion marks.\n",
      "      The Bundesbank spokesman noted that by bidding only 12.2\n",
      "  billion marks, below the outgoing 14.9 billion, banks\n",
      "  themselves had shown they felt they had plenty of liquidity.\n",
      "      Dealers said the Bundesbank is keen to prevent too much\n",
      "  liquidity accruing in the market, as that would blunt the\n",
      "  effectiveness of the security repurchase agreement, its main\n",
      "  open-market instrument for steering market interest rates. Two\n",
      "  further pacts are likely this month over the next two weeks.\n",
      "      The Bundesbank is currently steering call money between 3.6\n",
      "  and 3.8 pct, although short-term fluctuations outside that\n",
      "  range are possible, dealers said.\n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of documents\n",
    "documents = reuters.fileids()\n",
    "print(str(len(documents)) + \" documents\");\n",
    " \n",
    "train_docs_id = list(filter(lambda doc: doc.startswith(\"train\"),\n",
    "documents));\n",
    "print(str(len(train_docs_id)) + \" total train documents\");\n",
    " \n",
    "test_docs_id = list(filter(lambda doc: doc.startswith(\"test\"),documents));\n",
    "print(str(len(test_docs_id)) + \" total test documents\");\n",
    " \n",
    "# List of categories\n",
    "categories = reuters.categories();\n",
    "print(str(len(categories)) + \" categories\");\n",
    " \n",
    "# Documents in a category\n",
    "category_docs = reuters.fileids(\"interest\");\n",
    " \n",
    "# Words for a document\n",
    "document_id = category_docs[0]\n",
    "document_words = reuters.words(category_docs[0]);\n",
    "print(document_words);\n",
    " \n",
    "# Raw document\n",
    "print(reuters.raw(document_id));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-bidding",
   "metadata": {},
   "source": [
    "# Hyper-paramètres \n",
    "\n",
    "Avant d’appliquer les techniques traditionnelles d’apprentissage automatique, nous devons représenter et pondérer chaque document par rapport à l’ensemble des fonctionnalités textuelles. Nous allons appliquer les transformations suivantes :\n",
    "\n",
    "* Minuscules le contenu d’origine\n",
    "* Tokeniser le texte\n",
    "* Stem chacun des jetons\n",
    "* Pondérer chacune de ces caractéristiques, pour chaque document\n",
    "* Normaliser la représentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "proprietary-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = stopwords.words('english')\n",
    "charfilter = re.compile('[a-zA-Z]+')\n",
    "\n",
    "def simple_tokenizer(text):\n",
    "    #tokenizing the words:\n",
    "    #words = word_tokenize(text)\n",
    "    #converting all the tokens to lower case:\n",
    "    words = map(lambda word: word.lower(), text)\n",
    "    #let's remove every stopwords\n",
    "    words = [word for word in words if word not in stopWords]\n",
    "    #stemming all the tokens\n",
    "    tokens = (list(map(lambda token: PorterStemmer().stem(token), words)))\n",
    "    ntokens = list(filter(lambda token : charfilter.match(token),tokens))\n",
    "    return ntokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fantastic-paper",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "#permet de choisir de manière indépendant l'étiquête au choix\n",
    "def selectRandom(names):\n",
    "    return random.choice(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-dryer",
   "metadata": {},
   "source": [
    "Pour la realisation de la premièere partie de se mini projet nous aveons décidé d'utiliser le maodule Scikit-learn .\n",
    "\n",
    "* Scikit-learn est une bibliothèque d’apprentissage automatique open source pour python. Il fournit une variété d’algorithmes de régression, de classification et de clustering.\n",
    "* l'idée fondamental est de comprendre comment fonction la methode suivante :sklearn.cross_validation.train_test_split(*tableaux, **options)[source]\n",
    "* cette methode permet de diviser des tableaux ou des matrices en sous-ensembles aléatoires de train et de test.\n",
    "* dans un premier temps il faut determiner le bon format pour les paramètre entrée de cette methode. \n",
    "* cette méthode retourne une  Liste contenant la répartition des entrées entre le train et le test.\n",
    "\n",
    "pour les classifier nous avons choisi 3 classiffieur suivant:\n",
    "* GAUSSIANNB\n",
    "* LOGISTIC REGRESSION\n",
    "* K-NEAREST NEIGHBORS\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "distinct-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords, reuters\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "stop_words = stopwords.words(\"english\")\n",
    " \n",
    "# List of document ids \n",
    "def traitement(category):\n",
    "    train_labels=[]\n",
    "\n",
    "    train_docs = [reuters.raw(doc_id) for doc_id in documents]\n",
    "    for doc_id in documents:\n",
    "        if(doc_id in reuters.fileids(category)):\n",
    "            train_labels.append(\"TRUE\")\n",
    "        else:\n",
    "            train_labels.append(\"FALSE\")\n",
    "\n",
    "    # Tokenisation\n",
    "    vectorizer = TfidfVectorizer(stop_words=stop_words, tokenizer=simple_tokenizer)\n",
    "\n",
    "    vectorised_train_documents = vectorizer.fit_transform(train_docs).toarray()\n",
    "    return tts(vectorised_train_documents, train_labels, test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "olive-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# les scores de rappel, précision et f-mesure de chacun des trois \n",
    "classifieurs\n",
    "def evaluation(y_test):\n",
    "           # Evaluation\n",
    "    precision = precision_score(y_test, predictions, average='micro')\n",
    "    recall = recall_score(y_test, predictions, average='micro')\n",
    "    f1 = f1_score(y_test, predictions, average='micro')\n",
    "  \n",
    "    print(\"Micro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\"\n",
    "    .format(precision, recall, f1))\n",
    " \n",
    "    precision = precision_score(y_test, predictions, average='macro')\n",
    "    recall = recall_score(y_test, predictions, average='macro')\n",
    "    f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "    print(\"Macro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-renewal",
   "metadata": {},
   "source": [
    "# GaussianNB\n",
    "Naive Bayes est une technique de classification statistique basée sur le théorème de Bayes.\n",
    "\n",
    "dans le module Sklearn on l'utilise à travers les appelles suivant:\n",
    "* classifier = GaussianNB()\n",
    "* classifier.fit(X_train,  y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "meaning-friendship",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'e', 'f', 'g', 'h', 'j', 'l', 'n', 'p', 'r', 'u', 'v', 'w'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name catégorie: wheat\n",
      "predictions: ['FALSE' 'FALSE' 'FALSE' ... 'FALSE' 'FALSE' 'FALSE']\n",
      "Micro-average quality numbers\n",
      "Precision: 0.7261, Recall: 0.7261, F1-measure: 0.7261\n",
      "Macro-average quality numbers\n",
      "Precision: 0.5314, Recall: 0.7377, F1-measure: 0.4848\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords, reuters\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "#choix aleatoire de l'étiquette\n",
    "names =[\"grain\", \"wheat\", \"corn\"]     \n",
    "category = selectRandom(names)\n",
    "\n",
    "#traittement des données\n",
    "X_train, X_test, y_train, y_test = traitement(category)\n",
    "\n",
    "#classifier GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train,  y_train)\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "print(\"Name catégorie: \"+str(category))\n",
    "#prédiction avec la partie test de données\n",
    "print(\"predictions: \"+str(predictions))\n",
    "evaluation(y_test)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-correlation",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION\n",
    "La régression logistique utilise une fonction logistique pour prédire une variable dépendante binaire.\n",
    "pour l'utiliser Nous importons le package LogisticRegression comme suit :\n",
    "* from sklearn.linear_model import LogisticRegression\n",
    "puis appelé les méthodes suivantes:\n",
    "* reg_log = LogisticRegression()\n",
    "* reg_log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "marine-blind",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'e', 'f', 'g', 'h', 'j', 'l', 'n', 'p', 'r', 'u', 'v', 'w'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name catégorie: money-fx\n",
      "predictions: ['FALSE' 'FALSE' 'FALSE' ... 'FALSE' 'FALSE' 'FALSE']\n",
      "Micro-average quality numbers\n",
      "Precision: 0.7525, Recall: 0.7525, F1-measure: 0.7525\n",
      "Macro-average quality numbers\n",
      "Precision: 0.5205, Recall: 0.5626, F1-measure: 0.5011\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords, reuters\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "#choix aleatoire de l'étiquette\n",
    "names =[\"money-fx\", \"interest\", \"money-supply\"]     \n",
    "category = selectRandom(names)\n",
    "\n",
    "#traittement des données\n",
    "X_train, X_test, y_train, y_test = traitement(category)\n",
    "\n",
    "#classifier LOGISTIC REGRESSION\n",
    "reg_log = LogisticRegression()\n",
    "reg_log.fit(X_train, y_train)\n",
    "y_pred = reg_log.predict(X_test)\n",
    "\n",
    "print(\"Name catégorie: \"+str(category))\n",
    "#prédiction avec la partie test de données\n",
    "print(\"predictions: \"+str(predictions))\n",
    "evaluation(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-terry",
   "metadata": {},
   "source": [
    "# K-NEAREST NEIGHBORS\n",
    "Les K voisins les plus proches utilisent des calculs de distance euclidienne où la prédiction est la moyenne des k voisins les plus proches.\n",
    "\n",
    "pour l'utiliser Nous importons le package LogisticRegression comme suit :\n",
    "* from sklearn.neighbors import KNeighborsClassifier\n",
    "puis appelé les méthodes suivantes:\n",
    "* reg_knn = KNeighborsClassifier()\n",
    "* reg_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "enclosed-costs",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'e', 'f', 'g', 'h', 'j', 'l', 'n', 'p', 'r', 'u', 'v', 'w'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name catégorie: crude\n",
      "predictions: ['FALSE' 'FALSE' 'FALSE' ... 'FALSE' 'FALSE' 'FALSE']\n",
      "Micro-average quality numbers\n",
      "Precision: 0.7678, Recall: 0.7678, F1-measure: 0.7678\n",
      "Macro-average quality numbers\n",
      "Precision: 0.5326, Recall: 0.6229, F1-measure: 0.5144\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords, reuters\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "#choix aleatoire de l'étiquette\n",
    "names =[\"crude\",\"nat-gas\", \"gold\"]     \n",
    "category = selectRandom(names)\n",
    "\n",
    "#traittement des données\n",
    "X_train, X_test, y_train, y_test = traitement(category)\n",
    "\n",
    "#classifier K-NEAREST NEIGHBORS\n",
    "reg_knn = KNeighborsClassifier()\n",
    "reg_knn.fit(X_train, y_train)\n",
    "y_pred = reg_knn.predict(X_test)\n",
    "\n",
    "print(\"Name catégorie: \"+str(category))\n",
    "#prédiction avec la partie test de données\n",
    "print(\"predictions: \"+str(predictions))\n",
    "evaluation(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-sending",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "handmade-natural",
   "metadata": {},
   "source": [
    "* nous pouvons créer des classifieurs qui baliseront automatiquement les nouveaux documents avec des étiquettes de catégorie appropriées. Tout d’abord, nous construisons une liste de documents, étiquetés avec les catégories appropriées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "demographic-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters\n",
    "import random\n",
    "\n",
    "list_categorie = [\"money-fx\", \"interest\", \"money-supply\"]\n",
    "document = [(list(reuters.words(reuterid)), category)\n",
    "             for category in list_categorie\n",
    "             for reuterid in reuters.fileids(category)]\n",
    "random.shuffle(document)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-assault",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Classifieur multi-classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "organic-blues",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list_categorie = [\"money-fx\", \"grain\", \"crude\"]\n",
    "\n",
    "def get_custom_category(reuterid):\n",
    "    for category in list_categorie:\n",
    "        if reuterid in reuters.fileids(category):\n",
    "            return category\n",
    "    return 'other'\n",
    "\n",
    "document = []\n",
    "for reuterid in reuters.fileids():\n",
    "    custom_category = get_custom_category(reuterid)\n",
    "    document.append((list(reuters.words(reuterid)), custom_category))\n",
    "\n",
    "random.shuffle(document)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "passing-booth",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in document]\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "further-carter",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cloudy-provincial",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores :\n",
      "other\n",
      "Precision :\t 1.0\n",
      "Recall :\t 0.5813953488372093\n",
      "F-measure :\t 0.7352941176470589\n",
      "\n",
      "\n",
      "money-fx\n",
      "Precision :\t 0.2631578947368421\n",
      "Recall :\t 1.0\n",
      "F-measure :\t 0.41666666666666663\n",
      "\n",
      "\n",
      "crude\n",
      "Precision :\t 0.2\n",
      "Recall :\t 0.8333333333333334\n",
      "F-measure :\t 0.3225806451612903\n",
      "\n",
      "\n",
      "grain\n",
      "Precision :\t 0.3333333333333333\n",
      "Recall :\t 0.6666666666666666\n",
      "F-measure :\t 0.4444444444444444\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from nltk.metrics import precision, recall, f_measure\n",
    "\n",
    "\n",
    "ref_label_set = collections.defaultdict(set)\n",
    "test_label_set = collections.defaultdict(set)\n",
    "\n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    ref_label_set[label].add(i)\n",
    "    classification_label = classifier.classify(feats)\n",
    "    test_label_set[classification_label].add(i)\n",
    "\n",
    "print('Scores :')\n",
    "\n",
    "for label in ref_label_set.keys():\n",
    "    print(label)\n",
    "    print( 'Precision :\\t', precision(ref_label_set[label], test_label_set[label]) )\n",
    "    print( 'Recall :\\t', recall(ref_label_set[label], test_label_set[label]) )\n",
    "    print( 'F-measure :\\t', f_measure(ref_label_set[label], test_label_set[label]) )\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-population",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
